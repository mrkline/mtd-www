<PAGE>
<VAR match="VAR_ORIGIN" replace="../" />
<VAR match="VAR_CVSID" replace="Last updated: 26 Oct 2008, dedekind"/>
<INCLUDE file="../inc/header.tmpl" />

<VAR match="VAR_SEL_DOC" replace="selected" />
<VAR match="VAR_SEL_UBIFS" replace="selected" />
<PARSE file="../menu1.xml" />

<INCLUDE file="../inc/content.tmpl" />

<h1>UBIFS - UBI File-System</h1>

<h2>Table of contents</h2>
<ol>
	<li><a href="ubifs.html#L_rednote">Big red note</a></li>
	<li><a href="ubifs.html#L_overview">Overview</a></li>
	<li><a href="ubifs.html#L_source">Source code</a></li>
	<li><a href="ubifs.html#L_ml">Mailing list</a></li>
	<li><a href="ubifs.html#L_usptools">User-space tools</a></li>
	<li><a href="ubifs.html#L_scalability">Scalability</a></li>
	<li><a href="ubifs.html#L_writeback">Write-back support</a></li>
	<li><a href="ubifs.html#L_compression">Compression</a></li>
	<li><a href="ubifs.html#L_checksumming">Checksumming</a></li>
	<li><a href="ubifs.html#L_readahead">Read-ahead</a></li>
	<li><a href="ubifs.html#L_rootspace">Space for superuser</a></li>
	<li><a href="ubifs.html#L_xattr">Extended attributes</a></li>
	<li><a href="ubifs.html#L_mountopts">Mount options</a></li>
	<li><a href="ubifs.html#L_spaceacc">Flash space accounting issues</a></li>
	<li><a href="ubifs.html#L_documentation">Documentation</a></li>
	<li><a href="ubifs.html#L_how_send_bugreport">How to send an UBIFS bugreport?</a></li>
	<li><a href="ubifs.html#L_raw_vs_ftl">Raw flash vs. FTL devices</a></li>
</ol>



<h2><a name="L_rednote"><font color="red">Big red note</font></a></h2>

<p>One thing people have to understand when dealing with UBIFS is that UBIFS is
very different to any traditional file system - it <b>does not</b> work on top
of block devices (like hard drives, MMC/SD cards, USB flash drives, SSDs, etc).
UBIFS was designed to work on top of raw flash, which has nothing to do with
block devices. This is why UBIFS does not work on MMC cards or USB flash drives -
they look like block devices to the outside world because they implement
FTL (Flash Translation Layer) support in hardware, which simply speaking
emulates a block device on top of the built-in flash chip. Please, make sure
you understand the difference between raw flash and, say, MMC flash before
reading about UBIFS. <a href="L_raw_vs_ftl">This</a> section should help.</p>



<h2><a name="L_overview">Overview</a></h2>

<p>UBIFS is a new flash file system developed by Nokia engineers with help of
<a href="http://www.inf.u-szeged.hu/tanszekek/szoftverfejlesztes/starten.xml">
the University of Szeged</a>. In a way, UBIFS may be considered as the next
generation of the JFFS2 file-system.</p>

<p>JFFS2 file system works on top of MTD devices, but UBIFS works on top of UBI
volumes and cannot operate on top of MTD devices. In other words, there are 3
subsystems involved:</p>

<ul>
	<li><i>MTD subsystem</i>, which provides uniform interface to access
	flash chips. MTD provides an notion of MTD devices (e.g.,
	<code>/dev/mtd0</code>) which basically represent raw flash;</li>
	<li><i>UBI subsystem</i>, which is a wear-leveling and volume management
	system for flash devices; UBI works on top of MTD devices and provides
	a notion of UBI volumes; UBI volumes are higher level entities than MTD
	devices and they are devoid of many unpleasant issues MTD devices have
	(e.g., wearing and bad blocks); see <a href="ubi.html">here</a> for more
	information;</li>
	<li><i>UBIFS file system</i>, which works on top of UBI volumes.</li>
</ul>

<p>Here is a list of some of UBIFS features:</p>

<ul>
	<li><b>scalability</b> - UBIFS scales well with respect to flash size;
	namely,	mount time, memory consumption and I/O speed does not depend on
	flash size (it is not 100% true for memory consumption, but the
	dependency is very weak); UBIFS (not UBI!) should work fine for hundreds
	of GiB flashes; however, UBIFS depends on UBI which has scalability
	limitations (see <a href="ubi.html#L_scalability">here</a>);
	nonetheless, UBI/UBIFS stack scales much better than JFFS2, and if UBI
	becomes a bottleneck, it is always possible to implement UBI2 without
	changing UBIFS;</li>

	<li><b>fast mount</b> - unlike JFFS2, UBIFS does not have to scan whole
	media when mounting, it takes milliseconds for UBIFS to mount the
	media, and this does not depend on flash size; however, UBI
	initialization time depends on flash size and has to be taken into
	account (see <a href="ubi.html#L_scalability">here</a> for more
	details);</li>

	<li><b>write-back support</b> - this dramatically improves the
	throughput of the file system comparing to JFFS2, which is
	write-through; see <a href="ubifs.html#L_writeback">here</a> for more
	details;</li>

	<li><b>tolerance to unclean reboots</b> - UBIFS is a journaling file
	system and it tolerates sudden crashes and unclean reboots; UBIFS just
	replays the journal and recovers from the unclean reboot; mount time is
	a little bit slower in this case, because of the need to replay the
	journal, but UBIFS does not need to scan whole media, so it anyway
	takes fractions of a second to mount UBIFS; note, authors payed
	special attention to this UBIFS aspect, see
	<a href="../faq/ubifs.html#L_powercut">this</a> FAQ entry;</li>

	<li><b>fast I/O</b> - even with write-back disabled (e.g., if UBIFS is
	mounted	with the "<code>-o sync</code>" mount option) UBIFS shows good
	performance which is close to JFFS2 performance; bear in mind, it is
	extremely difficult to compete with JFFS2 in synchronous I/O, because
	JFFS2 does not maintain indexing data structures on flash, so it does
	not have the maintenance overhead, while UBIFS does have it; but UBIFS
	is still fast because of the way UBIFS commits the journal - it does
	not move the data physically from one place to another but instead, it
	just adds corresponding information to the file system index and picks
	different eraseblocks for the new journal (i.e., UBIFS has sort of
	"wandering" journal which constantly changes the position); there are
	other tricks like multi-headed journal which make UBIFS perform
	well;</li>

	<li><b>on-the-flight compression</b> - the data is stored in compressed
	form on the flash media, which makes it possible to put considerably
	more data to the flash than if the data was not compressed; this is very
	similar to what JFFS2 has; UBIFS also allows to switch the compression
	on/off on per-inode basis, which is very flexible; for example, one may
	switch the compression off by default and enable it only for certain
	files which are supposed to compress well; or one may switch
	compression on by default but disable it for supposedly uncompressible
	data like multimedia files; at the moment UBIFS supports only zlib and
	LZO compressors and it is not difficult to add more; see
	<a href="ubifs.html#L_compression">this</a> section for more
	information.</li>

	<li><b>recoverability</b> - UBIFS may be fully recovered if the indexing
	information gets corrupted; each piece of information in UBIFS has a
	header which describes this piece of information, and it is possible to
	fully reconstruct the file system index by scanning the flash media; to
	make it more clear, imaging you wiped out the FAT table on your FAT
	file system (FAT table is the index of the FS); for FAT FS it is fatal;
	but if you similarly wipe out UBIFS index, you still may re-construct
	it, although a special user-space tool would be required to do
	this;</li>

	<li><b>integrity</b> - UBIFS (as well as UBI) checksums everything it
	writes to the flash media to guarantee data integrity, UBIFS does not
	leave data or meta-data corruptions unnoticed (JFFS2 is doing the same,
	though); however, you may disable CRC checking for data to improve
	file-system read speed and lessen CPU usage - read
	<a href="ubifs.html#L_checksumming">this</a> section.</li>
</ul>



<h2><a name="L_source">Source code</a></h2>

<p>UBIFS is in mainline since 17 July 2008 and the first kernel release which
contains UBIFS is <code>2.6.27</code>. But since UBIFS is a very new file system,
it is recommended to pick the latest updates and fixes from the
<code>linux-next</code> branch of the UBIFS git tree:</p>

<code>git://git.infradead.org/ubifs-2.6.git</code>

<p><a href="http://git.infradead.org/ubifs-2.6.git">Here</a> is the
corresponding Git-web view.</p>

<p>The git tree has <code>master</code> and <code>linux-next</code> branches.
The <code>master</code> branch contains the most recent stuff which is often
incomplete, buggy, or not tested very well. This branch may be re-based from
time to time. The <code>linux-next</code> branch contains stable UBIFS updates
and fixes. This branch is included to the
<a href="http://linux.f-seidel.de/linux-next/">linux-next</a> git tree and goes
to main-line. The <code>linux-next</code> branch is never re-based. Thus,
unless you are an active UBIFS developer, use the <code>linux-next</code>
branch.</p>

<p>There are also <code>2.6.21</code>, <code>2.6.22</code>, <code>2.6.23</code>,
<code>2.6.24</code>, <code>2.6.25</code>, <code>2.6.26</code> and
<code>2.6.27</code>kernel back-ports, although they are not always up-to-date
and one may want to pick up additional patches from the main development git
tree to utilize the latest UBIFS version. The back-ports may be found at:</p>

<code>git://git.infradead.org/~dedekind/ubifs-v2.6.27.git</code><br/>
<code>git://git.infradead.org/~dedekind/ubifs-v2.6.26.git</code><br/>
<code>git://git.infradead.org/~dedekind/ubifs-v2.6.25.git</code><br/>
<code>git://git.infradead.org/~dedekind/ubifs-v2.6.24.git</code><br/>
<code>git://git.infradead.org/~dedekind/ubifs-v2.6.23.git</code><br/>
<code>git://git.infradead.org/~dedekind/ubifs-v2.6.22.git</code><br/>
<code>git://git.infradead.org/~dedekind/ubifs-v2.6.21.git</code>

<p>The Linux kernel is changing rapidly and it is rather difficult to make
back-ports fully match the mainline code, and the back-ports have various
limitations. Below are some of them</p>

<ul>
	<li>Since it is impossible to register memory shrinker in kernel
	versions <code>2.6.21</code> and <code>2.6.22</code>, the UBIFS
	shrinker does not work there, which means that UBIFS TNC cache never
	gets shrinked and the system may run out of memory if the file system
	is very large.</li>

	<li>Because of VFS interface changes since kernel version
	<code>2.6.24</code> (<code>write_begin()</code> instead of
	<code>prepare_write()</code>) back-ports <code>2.6.21</code>,
	<code>2.6.22</code>, and <code>2.6.23</code> may have slightly worse
	performance comparing to the mainline code.</li>
</ul>

<p>Thus, only <code>2.6.25</code> and higher version back-ports have full
UBIFS functionality and are not much different to the mainline UBIFS. Note, all
the back-port trees also have many MTD patches back-ported, and they have most
of the UBI changes back-ported. Also bear in mind, the back-port trees are not
going to be maintained forever and will be deleted at some point.</p>



<h2><a name="L_ml">Mailing list</a></h2>

<p>You are welcome to send feed-back, bug-reports, patches, etc to the
<a href="../mail.html">MTD mailing list</a>. Feel free to ask questions.
It might make sense to check the <a href="../faq/ubifs.html">UBIFS FAQ</a> as
well.</p>



<h2><a name="L_usptools">User-space tools</a></h2>

<p>There is only one UBIFS user-space tool at the moment -
<code>mkfs.ubifs</code>, which creates UBIFS images. The tool may be found in
the <i>MTD utils</i> repository (<code>mkfs.ubifs</code> sub-directory):</p>

<code>git://git.infradead.org/mtd-utils.git</code>

<p>The images produced by <code>mkfs.ubifs</code> may be written to
UBI volumes using <a href="ubi.html#L_usptools"><code>ubiupdatevol</code></a>
or may be further fed to the
<a href="ubi.html#L_usptools"><code>ubinize</code></a>
tool to create an UBI image which may be put to the MTD device.</p>



<h2><a name="L_scalability">Scalability</a></h2>

<p>All the data structures UBIFS is using are trees, so it scales
logarithmically in terms of flash size. However, UBI scales linearly
(see <a href="ubi.html#L_scalability">here</a>) which makes
overall UBI/UBIFS stack scalability linear. But the UBIFS authors believe it is
always possible to create logarithmically scalable UBI2 and improve the
situation. Current UBI should be OK for 2-16GiB flashes, depending on the
I/O speed and requirements.</p>

<p>Note, although the UBI scalability is linear, it anyway scales better much
than JFFS2, which was originally designed for small ~32MiB NOR flashes. JFFS2
has scalability issues on the "file system level", while UBI/UBIFS stack has
scalability issues only on lower "raw flash level". The following table
describes the issues in more details.</p>

<table border="2" cellpadding="4" cellspacing="0">
<tr>
	<td><b>Scalability issue</b></td>
	<td><b>JFFS2</b></td>
	<td><b>UBIFS</b></td>
</tr>

<tr>
	<td>Mount time linearly depends on the flash size</td>
	<td>True, the dependency is linear, because JFFS2 has to scan whole
	    flash media when mounting.</td>
	<td>UBIFS mount time does not depend on the flash size. But UBI needs
	    to scan the flash media, which is actually quicker than JFFS2
	    scanning. So overall, UBI/UBIFS has this linear dependency.</td>
</tr>

<tr>
	<td>Memory consumption linearly depends on the flash size</td>
	<td>True, the dependency is linear.</td>
	<td>UBIFS memory does depend on the flash size in the current
	    implementation, because the LPT shrinker is not implemented. But it
	    is not difficult to implement the LPT shrinker and get rid of the
	    dependency. It is not implemented only because the memory
	    consumption is too small to make the coding work worth it. UBI
	    memory consumption linearly depends on flash size. Thus, overall
	    UBI/UBIFS stack has the linear dependency.</td>
</tr>

<tr>
	<td>Mount time linearly depends on the file system contents</td>
	<td>True, the more data is stored on the file system, the longer it
	    takes to mount it, because JFFS2 has to do more scanning work.</td>
	<td>False, mount time does not depend on the file system contents. At
	    the worst case (if there was an unclean reboot), UBIFS has to scan
	    and replay the journal which has fixed and configurable size.</td>
</tr>

<tr>
	<td>Full file system checking is required after each mount</td>
	<td>True. JFFS2 has to check whole file system just after it has been
	    mounted in case of NAND flash. The checking involves reading all
	    nodes for each inode and checking their CRC checksums, which
	    consumes a lot of CPU. For example, this may be seen by running the
	    <code>top</code> utility just after JFFS2 has been mounted. This
	    slows down overall system boot-up time. Fundamentally, this is
	    needed because JFFS2 does not store space accounting information
	    (i.e., free/dirty space) on the flash media but instead, gathers
	    this information by scanning the flash media.</td>
	<td>False. UBIFS does not scan/check whole file system because it stores
	    the space accounting information on the flash media in the so-called
	    LPT (Logical eraseblock Properties Tree) tree.</td>
</tr>

<tr>
	<td>Memory consumption linearly depends on file system contents</td>
	<td>True. JFFS2 keeps a small data structure in RAM for each node on
	    flash, so the more data is stored on the flash media, the more
	    memory JFFS2 consumes.</td>
	<td>False. UBIFS memory consumption does not depend on how much data is
	    stored on the flash media.</td>
</tr>

<tr>
	<td>The first file access time linearly depends on its size</td>
	<td>True. JFFS2 has to keep in RAM so-called "fragment tree" for each
	    inode corresponding to an opened file. The fragment tree is an
	    in-memory RB-tree which is indexed by file offset and refers
	    on-flash nodes corresponding to this offset. The fragment tree is
	    <i>not</i> stored on the flash media. Instead, it is built
	    on-the-flight when the file is opened for the first time. To build
	    the fragment tree, JFFS2 has to read each data node corresponding
	    to this inode from the flash. This means, the larger is the file,
	    the longer it takes to open it for the first time. And the larger
	    is the file the more memory it takes when it is opened. Depending
	    on the system, JFFS2 becomes nearly unusable starting from certain
	    file size.</td>
	<td>False. UBIFS stores all the indexing information on the media in
	    the indexing B-tree. Whenever a piece of data has to be read from
	    the file system, the B-tree is looked-up and the corresponding
	    flash address to read is found. There is a TNC cache which caches
	    the B-tree nodes when the B-tree is looked-up, and the cache is
	    shrinkable, which means it might be shrunk when the kernel needs
	    more memory.</td>
</tr>

<tr>
	<td>File-system performance depends on I/O history</td>
	<td>True. Since JFFS2 is fully synchronous, it writes data to the flash
	    media as soon as the data arrives. If one changes few bytes in the
	    middle of a file, JFFS2 writes a data node which contains those
	    bytes to the flash. If there are many random small writes all
	    over the place, the file system becomes fragmented. JFFS2 merges
	    small fragments to 4KiB chunks, which involves re-compression and
	    re-writing the data. But this "de-fragmentation" is happening
	    during garbage collection and at random time, because JFFS2
	    wear-leveling algorithm is based on random eraseblock selection. So
	    if there were a lot of small writes, JFFS2 becomes slower some time
	    later - the performance just goes down out of the blue which makes
	    the system less predictable.</td>
	<td>False. UBIFS always writes in 4KiB chunks. This does not hurt the
	    performance much because of the write-back support: the data
	    changes do not go to the flash straight away - they are instead
	    deferred and are done later, when (hopefully) more data is changed
	    at the same data page and usually in background.</td>
</tr>
</table>



<h2><a name="L_writeback">Write-back support</a></h2>

<p>UBIFS supports write-back, which means that file changes do not go to the
flash media straight away, but they are cached and go to the flash later, when
it is absolutely necessary. This helps to greatly reduce the amount of I/O
which results in better performance. Write-back caching is standard technique
which is used by most file systems like <code>ext3</code> or
<code>XFS</code>.</p>

<p>In contrast, <code>JFFS2</code> does not have write-back support and all the
JFFS2 file system changes go the flash synchronously. Well, this is not
completely true and JFFS2 does have a small buffer of a NAND page size (if the
underlying flash is NAND). This buffer contains last written data and is
flushed once it is full. However, because the amount of cached data is very
small, JFFS2 is very close to a synchronous file system.</p>

<p>Write-back support requires the application programmers to take extra care
about synchronizing important files in time. Otherwise the files may corrupt or
disappear in case of power-cuts, which happen very often in many embedded
devices. Let's look at what Linux manual pages say:</p>

<pre>
$ man 2 write
....
NOTES
       A  successful return from write() does not make any guarantee that data
       has been committed to disk.  In fact, on some buggy implementations, it
       does  not  even guarantee that space has successfully been reserved for
       the data.  The only way to be sure is to call fsync(2)  after  you  are
       done writing all your data.
...
</pre>

<p>This is true for UBIFS (except of the "some buggy implementations" part,
because UBIFS does reserves space for cached dirty data). This is also true for
JFFS2, as well as for any other Linux file system.</p>

<p>However, some (perhaps not very good) user-space programmers do not take
write-back into account. They do not read man pages carefully. And some
applications which have been used in embedded systems which run JFFS2 worked
fine, because JFFS2 is so close to being synchronous. Of course, the
applications are buggy, but they appeared to work well enough with JFFS2. But
the bugs show up when UBIFS is used. Please, be careful and check/test your
applications with respect to power cut tolerance if you switch from JFFS2 to
UBIFS. The following is a list of useful hints and advices.</p>

<ul>
	<li>If you want to switch into synchronous mode, use
	<code>-o sync</code> option when mounting UBIFS; however, the file
	system performance may drop - be careful;</li>

	<li>Always keep in mind the above statement from the manual pages and
	run <code>fsync()</code> for all important files you change; of
	course, there is no need to synchronize "throw-away" temporary files;
	Just think how important is the file data and decide;</li>

	<li>If you want to be more accurate, you may use
	<code>fdatasync()</code>, in which cases only data changes will be
	flushed, but not inode meta-data changes (e.g., "<i>mtime</i>"
	or permissions); this might be more optimal than using
	<code>fsync()</code> if the synchronization is done often, e.g., in
	a loop; otherwise just stick with  <code>fsync()</code>;</li>

	<li>In shell, the <code>sync</code> command may be used, but it
	synchronizes whole file system which might be not very optimal; and
	there is a similar <i>libc</i> <code>sync()</code> function;</li>

	<li>Alternatively to <code>fdatasync()</code> you may use
	<code>O_SYNC</code> flag of the <code>open()</code> call; this will
	make sure all the data (but not meta-data) changes go to the media
	before the <code>write()</code> operation returns;</li>

	<li>It is possible to make certain inodes to be synchronous by
	default by setting the "<i>sync</i>" inode flag; in a shell, the
	<code>chattr +S</code> command may be used; in <i>C</i> programs,
	use the <code>FS_IOC_SETFLAGS</code> <code>ioctl</code> command;
	Note, the <a href="ubifs.html#L_usptools"><code>mkfs.ubifs</code></a>
	tool checks for the "<i>sync</i>" flag in the original FS tree, so
	the synchronous files in the original FS tree will be synchronous in
	the resulting UBIFS image.</li>
</ul>

<p>Let us stress that the above items are true for any Linux file system,
including <code>JFFS2</code>.</p>

<p><code>fsync()</code> may be called for directories - it synchronizes
the directory inode meta-data. The "<i>sync</i>" flag may also be set for
directories to make the directory inode synchronous. But the flag is inherited,
which means all new children of this directory will also have this flag. New
files and sub-directories of this directory will also be synchronous, and their
children, and so forth. This feature is very useful if one needs to create a
whole sub-tree of synchronous files and directories, or to make all new children
of some directory to be synchronous by default (e.g., <code>/etc</code>).</p>

<p>The <code>fdatasync()</code> call for directories is "no-op" in UBIFS and
all UBIFS operations which change directory entries are synchronous.
However, you should not to assume this for portability (e.g., this is not
true for <code>ext2</code>). Similarly, the "<i>dirsync</i>" inode flag has
no effect in UBIFS.</p>

<p>The functions mentioned above work on file-descriptors, not on streams
(<code>FILE *</code>). To synchronize a stream, you should first get its file
descriptor using the <code>fileno()</code> <i>libc</i> function, then flush the
stream using <code>fflush()</code>, and then synchronize the file using
<code>fsync()</code> or <code>fdatasync()</code>. You may use other
synchronization methods, but remember to flush the stream before synchronizing
the file. The <code>fflush()</code> function flushes the <i>libc</i>-level
buffers, while <code>sync()</code>, <code>fsync()</code>, etc flush
<i>kernel</i>-level buffers.</p>

<h4>Updating a file atomically</h4>

<p>This sub-section describes common technique of updating the contents of
a file atomically. This technique is applicable to other all POSIX-compatible
file systems, not only to UBIFS.</p>

<p>To atomically update the contents of file <code>foo</code>, you have to
first make a copy <code>bar</code> of this file, then change file
<code>bar</code>, synchronize file <code>bar</code>, and re-name
<code>bar</code> to <code>foo</code>. Because the re-name operation is atomic
(this is a <code>POSIX</code> requirement) and <code>bar</code> is
synchronized, the whole update operation is atomic as well. Indeed, if a power
cut happens, you will end up with intact <code>foo</code> and half-updated
<code>bar</code>, in which case the whole atomic update operation may be run
again.</p>



<h2><a name="L_compression">Compression</a></h2>

<p>UBIFS supports on-the-flight compression, which it compressed data
before writing them to the flash media, and de-compressed before reading them,
and this is absolutely transparent to the users. UBIFS compresses only regular
files data. Directories, device nodes and so on are not compressed. Meta-data
and the indexing information are not compressed as well.</p>

<p>At the moment UBIFS supports <i>LZO</i> and <i>zlib</i> compressors. Zlib
provides better compression ratio, but LZO is faster in both compression and
decompression. LZO is the default compressor for in-kernel UBIFS and for the
<code>mkfs.ubifs</code> utility. And of course you may disable UBIFS
compression altogether using the "<code>-x none</code>"
<a href="ubifs.html#L_usptools"><code>mkfs.ubifs</code></a> option.</p>

<p>UBIFS splits all data on 4KiB chunks and compresses each chunk
independently. This is not optimal, because larger chunks of data would
compress better, but this still provides noticeable flash space economy. For
example, real-life root file-system image for an ARM platform becomes ~40%
smaller with LZO compression and ~50% smaller with zlib compression. This
means that you may fit a 300MiB rootfs image into a 256MiB UBI volume and still
have about 100MiB of free space. However, the figures may be different
depending on the contents of the file-system. For example, if your file-system
mostly contains <code>mp3</code> files, UBIFS will be unable to efficiently
compress them, just because <code>mp3</code> files are already compressed.</p>

<p>In UBIFS it is possible to enable or disable compression individually for
each inode by setting or cleaning this compression flag. Note, the compression
flag of directories is inherited, which means that when files and
sub-directories are created, they inherit the compression flag of the parent
directory. Please, refer <a href="../faq/ubifs.html#L_comproff">this</a>
section for instruction about how the compression flag may be toggled.</p>

<p>It is also possible to combine LZO and zlib compressors, see
<a href="../faq/ubifs.html#L_favor_lzo">this</a> FAQ section.</p>

<p>It's also worth noting that JFFS2 LZO compression is a little bit different
to UBIFS zlib compression. UBIFS uses crypto-API deflate method, while JFFS2
uses zlib library directly. As a result, UBIFS and JFFS2 use different zlib
compression options. Namely, JFFS2 uses deflate level 3 and window bits 15,
while UBIFS uses deflate level 6 and window bits -11 (minus makes zlib avoid
putting a header to the output data stream). Experiments with compressing ARM
code <a href="../misc.html#L_ubifs_compr">showed</a> that JFFS2 compression
ratio is slightly smaller, decompression speed is also slightly slower, but
compression speed is faster.</p>



<h2><a name="L_checksumming">Checksumming</a></h2>

<p>Every piece of information UBIFS writes to the media has a CRC-32 checksum,
and UBIFS verifies the checksum for every piece of information it reads from
the media. CRC-32 is a quite strong function and any data corruption will most
probably be noticed. The same is true for UBI.</p>

<p>CRC-32 loads the CPU and makes the file-system slower - this is the price we
pay for providing very high data integrity level. But UBIFS allows to switch the
data checksumming off using the <code>no_chk_data_crc</code> mount option. If
UBIFS is mounted with this option, it does not check CRC-32 checksum for data,
but it does check it for the internal indexing information. And this option
only affects reading, not writing, because UBIFS always calculates CRC-32 when
writing the data.</p>

<p>Disabling checksum verification for data speeds-up file-system read
speed and reduces CPU usage. But of course, it also lowers the file-system
integrity level, so you should decide whether you want to use it or
not depending on your system requirements. In general, if you use SLC NAND
flash or NOR flash, it is probably fine to disable CRC-32. In case of MLC NAND
flash, you should probably be more careful. However, see
<a href="../faq/ubifs.html#L_ubifs_mlc">this</a> FAQ section for more
information about UBIFS on MLC NAND.</p>

<p>Note, currently UBIFS cannot disable CRC-32 calculations on write, because
UBIFS recovery process depends on in. When recovering from an unclean reboot
and re-playing the journal, UBIFS has to be able to detect broken and
half-written UBIFS nodes and drop them, and UBIFS depends on the CRC-32
checksum here. So the <code>no_chk_data_crc</code> mount option does not
improve UBIFS write speed. However, UBIFS writes speed should not be a problem
for a great deal of standard work-loads because of
<a href="ubifs.html#L_writeback">write-back</a> support.</p>

<p>In other words, if you use UBIFS with data CRC-32 checking disabled, you
still have the CRC-32 checksum attached to each piece of data, and you may
mount UBIFS with default options to enable CRC-32 checking at any time (e.g.,
when you suspect the file-system might be corrupted because you visited the
<a href="http://en.wikipedia.org/wiki/Large_Hadron_Collider">Large Hadron
Collider</a> and exposed your flash to proton beams).</p>



<h2><a name="L_readahead">Read-ahead</a></h2>

<p>Read-ahead is an optimization technique which makes the file system read
a little bit more data than users actually ask. The idea is that files are
often read sequentially from the beginning to the end, so the file system tries
to make next data available before the user actually asks for them.</p>

<p>Linux VFS is capable of doing read-ahead and this does not require any
support from the file system. This probably works well for traditional
block-based file systems, however this does not work well for UBIFS.
UBIFS works with UBI API, which works with MTD API, which is synchronous. MTD
API is pretty trivial and does not have any request queues. This means that VFS
blocks UBIFS readers and makes them wait for read-ahead process. In opposite,
block-device API is asynchronous and readers do not wait for read-ahead.</p>

<p>VFS read-ahead was designed for hard drives, and it was benchmarked with
hard-drives. But the nature of raw flash devices is very different to the nature
of Hard Drives Raw flash devices do not heave such a huge seek time as hard
drives do, so the techniques which work for HDDs do not necessarily work well
for flash.</p>

<p>That said, VFS read-ahead only slows UBIFS down instead of improving it,
so UBIFS disables VFS read-ahead. But UBIFS has its own internal read-ahead,
which we call "<i>bulk-read</i>". You may enable bulk-read using the
"<code>bulk_read</code>" UBIFS mount option.</p>

<p>Some flashes may read faster if the data is read at one go, rather than
at several read requests. For example, OneNAND can do "read-while-load" if
it reads more than one NAND page. So UBIFS may benefit from reading large
data chunks at one go, and this is exactly what bulk-read does.</p>

<p>If UBIFS notices that a file is being read sequentially (at least 3
sequential 4KiB blocks has been read), and if UBIFS sees that the further
file data resides sequentially at the same eraseblock, it starts reading data
ahead using large read requests, which makes it possible to read at higher
rates. So UBIFS reads more than it is asked to, and it pushes the read-ahead
data to the file caches, so the data become instantly available for the further
user read requests.</p>

<p>Here is an example. Suppose the user is reading a file sequentially. We are
lucky and the file is not fragmented on the media. Suppose LEB 25 contains data
nodes belonging to this file, and the data nodes are logically (in terms of
logical file offset) and physically (in terms of LEB/offset addresses)
sequential. Suppose user requests to read data node at LEB 25 offset 0. In this
case UBIFS will actually read whole LEB 25 at one go, then populate the file
cache with all the read data. And when the user asks the next piece of data,
it will already be in the cache.</p>

<p>Obviously, the bulk-read feature may slow UBIFS down in some work-loads, so
you should be careful. It is also worth noting that bulk-read feature cannot
help on highly fragmented file-systems. Although UBIFS does not fragment
file-systems (e.g., the Garbage-Collector does not re-order data nodes), but
UBIFS does not try to de-fragment them. For example, if you write a file
sequentially, it won't be fragmented. But if you write more than one file at
a time, they may become fragmented (well, this also depends on how write-back
flushes the changes), and UBIFS won't automatically de-fragment them. However,
it is possible to implement a background de-fragmentator. It is also possible
to have per-inode journal head and avoid mixing data nodes belonging to
different inodes in the same LEB. So there is room for improvements.</p>



<h2><a name="L_rootspace">Space for superuser</a></h2>

<p>UBIFS reserves some space for the superuser (root), which means that when
the file-system is full for normal users, there is still little space for the
super-user. File-systems like <code>ext2</code> have a similar feature.
<a href="ubifs.html#L_usptools"><code>mkfs.ubifs</code></a>
reserves ~1%, but at maximum ~5MiB of the space by default. The amount of
reserved space is stored in the UBIFS superblock and may be changed arbitrarily.
Currently <code>mkfs.ubifs</code> does not have a command line option to
override the defaults, but it should be trivial to implement.</p>

<p>By default only root may use the reserved space. But it is possible to
extend the list of power users who are able to utilize the reserved space.
UBIFS may record several user and group IDs at the superblock and allow them
to utilize the reserved space as well. But again, current
<code>mkfs.ubifs</code> utility does not have corresponding command line
options, but it should be trivial to implement them. UBIFS authors added the
mechanism, but did not use it so did not implement corresponding
<code>mkfs.ubifs</code> options.</p>

<p>Note, UBIFS prints the amount of reserved space when mounts the file-system.
See UBIFS messages in the system log.</p>



<h2><a name="L_xattr">Extended attributes</a></h2>

<p>UBIFS supports extended attributes if the corresponding configuration option
is enabled (no additional mount options are required). It supports the
<code>user</code>, <code>trusted</code>, and <code>security</code> name-spaces.
However, access control lists (ACL) support is not implemented.</p>



<h2><a name="L_mountopts">Mount options</a></h2>

<p>The following are UBIFS-specific mount options.</p>

<ul>
	<li><code>norm_unmount</code> (default) - commit on unmount; the
	journal is committed when the file system is unmounted so that the next
	mount does not have to replay the journal and it becomes very
	fast;</li>

	<li><code>fast_umount</code> - do not commit on unmount; this option
	makes unmount faster, but the next mount slower because of the need to
	replay the uncommitted journal;</li>

	<li><code>chk_data_crc</code> (default) - check data CRC-32
	checksums;</li>

	<li><code>no_chk_data_crc</code> - do not check data CRC-32 checksums,
	see <a href="ubifs.html#L_checksumming">this</a> section for more
	details;</li>

	<li><code>bulk_read</code> - enable bulk-read, see
	<a href="ubifs.html#L_readahead">here</a>;</li>

	<li><code>no_bulk_read</code> (default) - do not bulk-read.</li>
</ul>

<p>Example:</p>

<pre>
$ mount -t ubifs -o fast_umount,no_chk_data_crc ubi0:rootfs /mnt/ubifs
</pre>

<p>mounts UBIFS file-system to <code>/mnt/ubifs</code>, enables fast
unmount and disables data CRC checking.</p>

<p>Besides, UBIFS supports the standard <code>sync</code> mount option which
may be used to disable UBIFS write-back and write-buffer caching and make it
fully synchronous. Note, UBIFS does not support "<i>atime</i>", so the
<code>atime</code> mount option has no effect.</p>



<h2><a name="L_spaceacc">Flash space accounting issues</a></h2>

<p>Traditional file systems like <code>ext2</code> can easily calculate amount
of free space. The calculation is usually quite precise and users are
accustomed to this. However, the situation is very different in UBIFS - it
cannot really report precise amount of free space which confuses users.
Instead, it reports <i>minimum</i> amount of free space, which usually
less than the real amount. Sometimes the mistake may be very high. For example,
UBIFS may report (via the <code>statfs()</code> system call) that there is no
free space, but one would still be able to write quite a lot.</p>

<p>To put it differently, UBIFS is often <i>lying</i> about the amount of free
space it has. As a rule, it may fit considerably more bytes than it reports.
However, it never reports more free space than it has. It reports less, and
very rarely it may report the exact amount. And this is not because UBIFS
authors are jerks, there are fundamental reasons for this, which are discussed
below.</p>

<h4>Effect of compression</h4>

<p>The first factor is UBIFS on-flight compression. Users usually seem to expect
that if file system reports <i>N</i> bytes of free space, than it is possible
to create an <i>N</i>-byte file. And because of the compression, this is not
quite true for UBIFS. Depending on how well the file data compresses, UBIFS may
fit several times more than it reports.</p>

<p>When UBIFS calculates free space, it does not a-priori know anything about
the data which is going to be written, so it cannot take into account the
compression, so it always assumes the worst-case scenario when the data does
not compress.</p>

<p>Well, this does not sound as a big issue. However, compression becomes an
issue for free space reporting when compression is combined with
<a href="ubi.html#L_writeback">write-back</a>. Namely, UBIFS cannot know how
well the cached dirty data would compress, and the only way to find this out is
to actually compress it. See below.</p>

<h4>Effect of write-back</h4>

<p>Suppose there are <i>X</i> bytes of dirty file data in the page cache. They
will be flushed to the flash media later, but they are in RAM so far. UBIFS
(namely, the budgeting sub-system) has <i>reserved</i> <i>X</i> + <i>O</i>
bytes on the flash media for this data, where <i>O</i> is file system overhead
(e.g., the data has to be indexed, each data node has a header, etc).</p>

<p>The problem is that UBIFS cannot accurately calculate <i>X</i> and <i>O</i>,
and it uses pessimistic worst-case calculations, so that when the cached data
are flushed, they may take considerably less flash space than the reserved
<i>X</i> + <i>O</i>. For example, this may lead to the following
situations.</p>

<pre>
$ df
Filesystem           1K-blocks      Used Available Use% Mounted on
ubi0:ubifs               49568     49568         0 100% /mnt/ubifs
$ sync
$ df
Filesystem           1K-blocks      Used Available Use% Mounted on
ubi0:ubifs               49568     39164      7428  85% /mnt/ubifs
</pre>

<p>First time <code>df</code> reported zero free space, but after
the <code>sync</code> it reported <code>15%</code> free space. This is because
there were a lot of cached dirty data, and UBIFS reserved all flash space
for them. But once the data has reached the flash media, they took considerably
less flash space.</p>

<p>Here are the reasons why UBIFS reserves more space than it is needed.</p>

<ul>
	<li>One of the reasons is again related to the compression. The data is
	stored in the uncompressed form in the cache, and UBIFS does know how
	well it would compress, so it assumes the data wouldn't compress at all.
	However, real-life data usually compresses quite well (unless it
	already compressed, e.g. it belongs to a <code>.tgz</code> or
	<code>.mp3</code> file). This leads to major over-estimation of the
	<i>X</i> component.</li>

	<li>Due to the design, UBIFS nodes never cross logical eraseblock (or
	LEB, see <a href="ubi.html#L_overview">here</a>) boundaries, so there
	are small spots of wasted space at the end of eraseblocks. The amount
	of this wasted flash space depends on the data and in which order this
	data has been written or changed. And traditionally UBIFS
	pessimistically assumes maximum possible amount of wasted space, which
	leads to over-estimation of the <i>O</i> component. See the next
	sub-section.</li>
</ul>

<p>Thus, UBIFS reports <i>more accurate</i> free space value if it is
synchronized.</p>

<h4>Wastage</h4>

<p>As it was mentioned above, UBIFS nodes do not cross LEB boundaries. Consider
the following numbers:</p>

<ul>
	<li>maximum UBIFS node size (non-compressed data node) is 4256
	bytes;</li>
	<li>smallest UBIFS node size (a data node with 8 bytes of data,
	corresponding to a file tail) is  56 bytes;</li>
	<li>depending on name length, directory entry nodes take 56-304
	bytes;</li>
	<li>typical LEB size in case of NAND flash with 128KiB physical
	eraseblocks and 2048 bytes NAND page is 126KiB (or 124KiB if  the NAND
	chip does not support sub-pages, see
	<a href="../faq/ubi.html#L_find_min_io_size">here</a>).</li>
</ul>

<p>Thus, if the vast majority of nodes on the flash were non-compressed data
nodes, UBIFS would waste 1344 bytes at the ends of 126KiB LEBs. But real-life
data is often compressible, so data node sizes vary, and the amount of wasted
space at the ends of eraseblocks varies from 0 to 4255.</p>

<p>UBIFS is doing some job to put small nodes like directory entries to the
ends of LEBs to lessen the amount of wasted space, but it is not ideal and
UBIFS still may waste unnecessarily large chunks of flash space at the ends of
eraseblocks.</p>

<p>When reporting free space, UBIFS does not know which kind of data is going
to be written to the flash media, and in which sequence. Thus, it assumes the
maximum possible wastage of 4255 bytes per LEB. This calculation is too
pessimistic for most real-life situations and the average real-life
wastage is considerably less than 4255 bytes per LEB. However, UBIFS reports
the absolute minimum amount of free space user-space applications may count
on.</p>

<p>The above means that the larger is LEB size, the better is UBIFS free space
prediction. E.g., UBIFS is better in this respect on NANDs with 128KiB
eraseblock size, comparing to NANDs with 16KiB eraseblock size.</p>

<h4>Dirty space</h4>

<p>Dirty space is the flash space occupied by UBIFS nodes which were
invalidated because they were changed or removed. For example, if the contents
of a file is re-written, than corresponding data nodes are invalidated and new
data nodes are written to the flash media. The invalidated nodes comprise dirty
space. There are other mechanisms how dirty space appears as well.</p>

<p>UBIFS cannot re-use dirty space straight away, because corresponding flash
areas do not contain all 0xFF bytes. Before dirty space can be re-used, UBIFS
has to garbage-collect corresponding LEBs. The idea of Garbage collector which
reclaims dirty space is the same as in JFFS2. Please, refer the
<a href="http://sources.redhat.com/jffs2/jffs2.pdf">JFFS2 design document</a>
for more information.</p>

<p>Roughly, UBIFS garbage collector picks a victim LEB which has some dirty
space and moves valid UBIFS nodes from the victim LEB to the LEB which was
reserved for GC. This produces some amount of free space at the end of the
reserved LEB. Then GC pick new victim LEB, and moves the data to the reserved
LEB. When the reserved LEB is full, UBIFS picks another empty LEB (e.g., the
old victim which had been made free a step ago), and continues moving nodes
from the victim LEB to the new reserved LEB. The process continues until a full
empty LEB is produced.</p>

<p>UBIFS has a notion of minimum I/O unit size, which characterizes minimum
amount of data which may be written to the flash (see
<a href="../faq/ubi.html#L_find_min_io_size">here</a> for more information).
Typically, UBIFS works on large-page NAND flashes and min. I/O size is 2KiB.</p>

<p>Consider a situation when GC picks eraseblocks with less than min. I/O unit
size dirty space. When all nodes from the victim LEB have been moved to the
reserved LEB, the last min. I/O unit of the reserved LEB has to be written to
the flash media, which means no space would be reclaimed. The reason why the
last min. I/O unit of the reserved LEB has to me written immediately is because
the victim LEB cannot be erased <i>before</i> all the moved nodes have reached
the media. Indeed, otherwise an unclean reboot would result in lost data.</p>

<p>Well, things are actually not that simple and UBIFS GC actually tries not to
waste space, but it is not always possible and UBIFS GC is far from being
ideal. Anyway, what matters is that UBIFS cannot always reclaim dirty space if
the amount of it is less than min. I/O unit size.</p>

<p>When UBIFS reports free space to the users, it treats dirty space as
available for new data, because after garbage-collection dirty space becomes
free space. But we have just showed, UBIFS cannot reclaim <i>all</i> dirty
space and turn it into free space. Worse, UBIFS does not precisely know how
much dirty space it can reclaim. So it again uses pessimistic calculations.</p>

<p>Thus, the less dirty space the FS has, and the smaller is dirty space
fragmentation, the more precise is UBIFS free space reporting. In practice this
means that a file system which is close to be full has less accurate free
space reporting comparing to a less full file system, because this file system
presumably has more dirty space.</p>

<p>Note, to fix this issue, UBIFS would need to run GC in
<code>statfs()</code>, which would turn as much dirty space as possible into
free space, which would result in more precise free space reporting. However,
this would make <code>statfs()</code> very slow. Another possibility would be
to implement background GC in UBIFS (just like in JFFS2), which would lessen
effect of dirty space with time.</p>

<h4>Precise index size is not known</h4>

<p>As you probably know, UBIFS maintain the FS index on flash. The index takes
some flash space. There also UBIFS journal, which contain FS data. The FS data
in the journal is not indexed, which means that on-flash index does not refer
it. Instead, UBIFS keeps indexing information for the journal in RAM. When the
file system is mounted, UBIFS has to scan the journal and build this part of
the index in RAM. So the journal is like a small JFFS2 file system inside
UBIFS.</p>

<p>The journal becomes indexed as the result of the commit operation. During
the commit UBIFS updates the on-flash index and makes it refer information in
the journal. Then UBIFS picks other LEBs for the new journal, so the journal
changes is position after the commit.</p>

<p>UBIFS maintains precise accounting of the index size. That is, UBIFS always
knows how many bytes the on-flash index takes. However, UBIFS does not
know precisely how much will the index grow (or shrink) after the commit. This
means, it does not know whether how much will the index size change after the
journal data references will be included into the on-flash index. And UBIFS
again makes pessimistic calculations here and assumes worst-case scenario.</p>

<p>However, after the commit operation, UBIFS knows exact index size again. The
<code>sync()</code> system not only flushes all dirty data, but it also call
makes UBIFS commit the journal. This means that file system synchronization the
makes free space prediction mistake lower.</p>

<p>It is worth noting that this is not a fundamental thing. It is just an UBIFS
implementation detail. UBIFS could calculate precise index size without actually
running the commit operation, but the UBIFS authors found it difficult to
implement. And the effect of the index size uncertainty should be low.</p>



<h2><a name="L_documentation">Documentation</a></h2>

<p>If flash file systems is a completely new area for you, it is recommended
to start from learning JFFS2, because many basic ideas are the same in UBIFS.
Read the <a href="http://sources.redhat.com/jffs2/jffs2.pdf">JFFS2 design</a>
document.</p>

<p>You may find the description of main JFFS2 issues, as well as very basic
UBIFS ideas in the <a href="JFFS3design.pdf">JFFS3 design</a> document.
Remember, the document in general is old and out-of-date. We do not use the
"JFFS3" name anymore, and JFFS3 was re-named to UBIFS. The document was written
when UBI did not exist and the document assumes that JFFS3 is talking directly
to the MTD device, just like JFFS2. However, the <i>JFFS2 overview</i>,
<i>JFFS3 Requirements</i>, and <i>Introduction to JFFS3</i> chapters are still
mostly valid and give a good introduction into basic UBIFS ideas like
wandering tree and the journal. Although please note, that the superblock
description is irrelevant for UBIFS. UBIFS is based on UBI and does not need
that trick. However, the superblock location idea may be used to create new
scalable UBI2 layer.</p>

<p>This web-page as well as the <a href="../faq/ubifs.html">UBIFS FAQ</a>
contains a plenty of UBIFS information. And you have to study UBI as well,
because UBIFS depends on the services provided by the UBI layer. See the
<a href="ubi.html">UBI documentation</a> and <a href="../faq/ubi.html">UBI
FAQ</a> sections.</p>

<p>There is an <a href="ubifs_whitepaper.pdf">UBIFS white-paper</a> document
available as well. However, it might be rather difficult for newbies, so we
recommend to start with the JFFS3 design document. The UBIFS white-paper gives
a complete UBIFS design picture and describes the UBIFS internals. The
white-paper does not contain some details which you may find at this web-page
or in the UBIFS FAQ, and vice-versa.</p>

<p>And finally, there is <a href="ubifs.html#L_source">UBIFS source code</a>.
The code has a great deal of comments, so we recommend to look there if
you need all the details. And of course, you are welcome to ask questions
at the <a href="ubifs.html#L_ml">UBIFS mailing list.</a></p>



<h2><a name="L_how_send_bugreport">How to send an UBIFS bugreport?</a></h2>

<p>Before sending a bug report, please:</p>
<ul>
	<li>make sure you have compiled kernel symbols in
	(<code>CONFIG_KALLSYMS_ALL=y</code> in <code>.config</code>);</li>

	<li>mark the <b>Enable debugging</b> check-box in the kernel
	configuration menu(<code>CONFIG_UBIFS_FS_DEBUG=y</code> in
	<code>.config</code>); Please, do not enable other debugging
	sub-options like debugging messages unless you know what you are
	doing;</li>
</ul>

<p>Then reproduce the bug (hopefully it is reproducible). Attach all the
bug-related messages including the UBIFS messages from the kernel ring buffer,
which may be collected using the <code>dmesg</code> utility or using
<code>minicom</code> with serial console capturing. And of course, it is wise
to describe how the problem can be reproduced. The bugreport should be sent to
the <a href="../mail.html">MTD mailing list</a>.</p>

<p>Note, sometimes UBIFS bugs may appear to be UBI bugs. If you suspect
there are UBI problems, please, also enable UBI debugging (see
<a href="../faq/ubi.html#L_how_debugt">here</a>).</p>



<h2><a name="L_raw_vs_ftl">Raw flash vs. FTL devices</a></h2>

<p>FTL stands for "Flash Translation Layer" and it is software which emulates
a block device on top of flash hardware. At early days FTL ran on the
host computer. For example, old PCMCIA flash devices were essentially raw flash
devices, and the PCMCIA standard defined the media storage format for them. So
the host computer had to run the FTL software driver which implements PCMCIA
FTL. However, nowadays FTL is usually firmware, and it is run by the controller
which is built intro the storage device. For example, if you look inside an USB
flash drive, you'll find there a NAND chip (or several of them), and a
micro-controller, which runs FTL firmware. Some USB flash drives are known to
have quite powerful ARM processors inside. Similarly, MMC, eMMC, SD, SSD, and
other FTL devices have a built-in controller which runs FTL firmware.</p>

<p>All FTL devices have an interface which provides block I/O access. Well, the
interfaces are different and they are defined by different specifications,
e.g., MMC, eMMC, SD, USB mass storage, ATA, and so on. But all of them provide
block-based access to the device. By block-based access we mean that whole
device is represented as an linear array of (usually 512-byte) blocks. Each
block may be read or written.</p>

<p>Linux has an abstraction of a block device. For example hard drives are
block devices. Linux has many file systems and the block I/O subsystem, which
includes elevators and so on which have been created to work with block
devices (historically - hard drives). So the idea is that the same software may
be used with FTL devices. For example, you may use FAT file system on your MMC
card, or ext3 file system or your SSD.</p>

<p>Although most flashes on the commodity hardware have FTL, there are systems
which have bare flashes and do not use FTL. Those are mostly various handheld
devices and embedded systems. Raw flash devices are very different to block
devices. They have different work model, they have tighter constraints and more
issues than block devices. In case of FTL devices these constraints and issues
are hidden, but in case of raw flash the software has to deal with them. Please,
refer <a href="../faq/general.html#L_mtd_vs_hdd">this</a> table for the some
more details about the difference between block devices and raw flashes.</p>

<p>UBIFS file system has been designed for raw flash. It does work with block
devices and it assumes the raw flash device model. In other words, it assumes
the device has eraseblocks, which may be written to, read from, or erased.
UBIFS takes care of writing all data out-of-place, doing garbage-collection
and so on. UBIFS utilizes UBI, which is doing stuff like wear-leveling and
bad eraseblock handling. All these things are not normally needed for block
devices.</p>

<p>Very often people ask questions like "why would one need to use raw
flash and why not just use eMMC, or something like this?". Well, there is no
simple answer, and the following is what UBIFS developers think. Please,
take it as just our opinion and take into account the date of this writing (15
October 2008). The answer is given in a form of a list of non-structured items,
and the reader should structure and interpret it in a way which is appropriate
for his system. And because mass storage systems mostly use NAND flash (modern
FTL devices have NAND flash arrays inside), the answer talk specifically about
NAND flashes. Also, we'd like to emphasize that we do not give general
recommendations and everything depends on system requirements.</p>

<ul>
	<li>Bare NAND chips are cheaper and simpler, which is very important
	for small system. However, it seems like the industry pushes FTL
	devices forward and the situation is not that simple and obvious
	anymore. Indeed, an FTL devise is more complex than a raw NAND of
	similar size, because FTL device has to have additional controller
	and so on. But since the industry tends to produce a lot of FTL devices,
	and actually sell a lot of them, the price is going down.</li>

	<li>If you need an flash storage where you are going to use FAT file
	system, then in most cases you should stick with an FTL device (eMMC,
	MMC, SD or whatever). Just make sure the FTL device is doing proper
	wear-leveling. We believe the good brand FTL devices do it well.</li>

	<li>The other situation is when you are going to use your FTL device
	for system storage (e.g. for rootfs) and use a more robust file system
	like ext3. In this situation you should take into account various
	system requirements like tolerance to sudden power cuts. The following
	items are mostly related to system storage situations.</li>

	<li>FTL devices are "black boxes". FTL algorithms are normally vendor
	secrets. But we know that NAND flash has issues like wear-leveling,
	bad blocks handling, read-disturb and so on. And it is important to get
	them right, especially in case of MLC NAND flash, which may have very
	short eraseblock life-time (e.g., only 1000 erase-cycles). But because
	FTL algorithms are closed, it is difficult to be sure whether a specific
	FTL device gets everything right or not.</li>

	<li>If you start thinking about how FTL could be implemented, you
	realize that it must do things like garbage collection (sometimes
	referred to as "reclaim process"). And flash hardware pretty much
	requires most writes to be out-of-place. But how does FTL behaves in
	case of sudden power-cuts? What if a power-cut happens while it is in
	the middle of doing garbage collection? Does the FTL device guarantee
	that the data which was on the flash media before the power cut happens
	will not disappear or become corrupted?</li>

	<li>The power-cut tolerance may be tested, while it is quite difficult
	to test stuff like wear-leveling or read-disturb handling, because it
	may require too much time.</li>

	<li>We have heard reports that some USB flash drives wear out very
	quickly, i.e., they start reporting I/O errors after few weeks of
	intensive use. This means that FTL does not do proper wear-leveling.
	But this does not mean that all USB flash drives are bad, but you just
	should be careful.</li>

	<li>We have heard reports that MMC and SD cards corrupt and loose data
	if power is cut during writing. Even the data which was there long time
	before may corrupt or disappear. This means that they have bad FTL
	which does not do things properly. But again, this does not have to be
	true for all MMCs and SDs - there are many different vendors. But
	again, you should be careful.</li>

	<li>In general, if you glance back into the history, many FTL devices
	were mostly used with FAT file system for storing stuff like photo and
	video. FAT file system is not reliable by definition, which suggests
	that FTL devices may also not be very reliable, just because
	historically this was not really required. Indeed, it is not a big deal
	to loose a couple of photos. However, it is crucial to make sure that
	system libraries do not corrupt because of power-cuts.</li>

	<li>Good FTL, especially if it deals with MLC NAND (which is used in
	modern mass storage devices) must be a rather complex piece of
	software. Implementing it in firmware might be a not very simple task.
	And running it might require a powerful controller. Obviously, we may
	suspect that vendors go for various kind of tricks or compromises to
	keep their devices "good enough" and cheap. For example, it is known
	that some vendors optimize their FTL devices for FAT, and if you start
	using ext3 on top of it, you might face some unexpected problems or the
	device may become not as good as you would imagine. Again, with closed
	FTL it is often difficult to verify this..</li>

	<li>SSD drives are probably very different to eMMC, MMC/SD etc. We have
	not worked with SSD drives. They are expensive and they probably have
	powerful CPUs inside, which run complex	firmware which is probably
	getting things righ.</li>

	<li>FTL devices are becoming more popular and better, although it is
	not easy to distinguish between good and bad FTL devices (of course
	vendors would assure you their device is perfect). Generally, there
	is nothing wrong in using an FTL device as long as you trust it, or
	have tested it, or it simply fit your system requirements.</li>

	<li>In case of raw flash we exactly know what we are doing. UBI/UBIFS
	handles	all aspects of NAND flash like bad erase-blocks and
	wear-leveling. It guarantees power-cut tolerance. It is open and
	available, so you may always validate, test, and fix it. In opposite,
	it is not that simple to fix firmware bugs.</li>

	<li>Theoretically, UBIFS may do better job, because it knows much more
	information about the files than FTL. For example, UBIFS knows about
	deleted files, while FTL does not, so FTL may do unneeded work trying
	to preserve the sectors belonging to deleted files. However, some FTL
	devices support "discard" requests and may benefit from the file system
	hints about unused sectors. Nevertheless, in general, UBIFS should do
	better job on a bare NAND, than a traditional FS on an FTL device with
	a similar NAND chip. On the other hand, FTL devices may	include
	multiple NAND chips, highly parallelise things and provide fast I/O.
	Probably SSD is a good example. But this may affect the cost.</li>

	<li>Obviously, the advantage of FTL devices is that you use old and
	trusted software on top of them.</li>
</ul>

<p>So it is indeed difficult to give an answer. Just think about cons and pros,
take into account your system requirements and decide. Nonetheless, raw flashes
are used, mostly in the embedded world, and this is why UBIFS has been
developed.</p>



<INCLUDE file="../inc/footer.tmpl" />
</PAGE>
