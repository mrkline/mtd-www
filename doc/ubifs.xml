<PAGE>
<VAR match="VAR_ORIGIN" replace="../" />
<VAR match="VAR_CVSID" replace="Last updated: 16 Oct 2008, dedekind"/>
<INCLUDE file="../inc/header.tmpl" />

<VAR match="VAR_SEL_DOC" replace="selected" />
<VAR match="VAR_SEL_UBIFS" replace="selected" />
<PARSE file="../menu1.xml" />

<INCLUDE file="../inc/content.tmpl" />

<h1>UBIFS - UBI File-System</h1>

<h2>Table of contents</h2>
<ol>
	<li><a href="ubifs.html#L_rednote">Big red note</a></li>
	<li><a href="ubifs.html#L_overview">Overview</a></li>
	<li><a href="ubifs.html#L_status">Current status</a></li>
	<li><a href="ubifs.html#L_source">Source code</a></li>
	<li><a href="ubifs.html#L_ml">Mailing list</a></li>
	<li><a href="ubifs.html#L_usptools">User-space tools</a></li>
	<li><a href="ubifs.html#L_scalability">Scalability</a></li>
	<li><a href="ubifs.html#L_writeback">Write-back support</a></li>
	<li><a href="ubifs.html#L_xattr">Extended attributes</a></li>
	<li><a href="ubifs.html#L_mountopts">Mount options</a></li>
	<li><a href="ubifs.html#L_spaceacc">Flash space accounting issues</a></li>
	<li><a href="ubifs.html#L_documentation">Documentation</a></li>
	<li><a href="ubifs.html#L_how_send_bugreport">How to send an UBIFS bugreport?</a></li>
	<li><a href="ubifs.html#L_raw_vs_ftl">Raw flash vs. FTL devices</a></li>
</ol>



<h2><a name="L_rednote"><font color="red">Big red note</font></a></h2>

<p>One thing people have to understand when dealing with UBIFS is that UBIFS is
very different to any traditional file system - it <b>does not</b> work on top
of block devices (like hard drives, MMC/SD cards, USB flash drives, SSDs, etc).
UBIFS was designed to work on top of raw flash, which has nothing to do with
block devices. This is why UBIFS does not work on MMC cards or USB flash drives -
they look like block devices to the outside world because they implement
FTL (Flash Translation Layer) support in hardware, which simply speaking
emulates a block device on top of the built-in flash chip. Please, make sure
you understand the difference between raw flash and, say, MMC flash before
reading about UBIFS. <a href="L_raw_vs_ftl">This</a> section should help.</p>



<h2><a name="L_status">Current status</a></h2>

<p>UBIFS has proved to be fairly stable, however it needs more testing, review,
and tuning (e.g., finding optimal journal size, etc). It also needs some
profiling and bottleneck hunting.</p>



<h2><a name="L_source">Source code</a></h2>

<p>UBIFS is in mainline since 17 July 2008 and the first kernel release which
contains UBIFS is <code>2.6.27</code>. But since UBIFS is a very new file system,
it is recommended to pick the latest updates and fixes from the UBIFS git
tree:</p>

<code>git://git.infradead.org/~dedekind/ubifs-2.6.git</code>

<p>The git tree has <code>master</code> and <code>linux-next</code> branches.
The <code>master</code> branch contains the most recent stuff which is often
incomplete, buggy, or not tested very well. This branch may be re-based from
time to time. The <code>linux-next</code> branch contains stable UBIFS updates
and fixes. This branch is included to the
<a href="http://linux.f-seidel.de/linux-next/">linux-next</a> git tree and goes
to main-line. The <code>linux-next</code> branch is never re-based. Thus,
unless you are an active UBIFS developer, use the <code>linux-next</code>
branch.</p>

<p>There are also <code>2.6.21</code>, <code>2.6.22</code>, <code>2.6.23</code>,
<code>2.6.24</code>, <code>2.6.25</code>, and <code>2.6.26</code> kernel
back-ports, although they are not always up-to-date and one may want to pick up
additional patches from the main development git tree to utilize the latest
UBIFS version. The back-ports may be found at:</p>

<code>git://git.infradead.org/~dedekind/ubifs-v2.6.26.git</code><br/>
<code>git://git.infradead.org/~dedekind/ubifs-v2.6.25.git</code><br/>
<code>git://git.infradead.org/~dedekind/ubifs-v2.6.24.git</code><br/>
<code>git://git.infradead.org/~dedekind/ubifs-v2.6.23.git</code><br/>
<code>git://git.infradead.org/~dedekind/ubifs-v2.6.22.git</code><br/>
<code>git://git.infradead.org/~dedekind/ubifs-v2.6.21.git</code>

<p>Because the Linux kernel is changing rapidly, it is rather difficult
to make back-ports match the mainline code, and different back-ports have
different limitations. Below are some of them.</p>

<ul>
	<li>Since it is impossible to register memory shrinker in kernel
	versions <code>2.6.21</code> and <code>2.6.22</code>, the UBIFS
	shrinker does not work there, which means the UBIFS TNC cache never
	gets shrinked and the system may run out of memory if the file system
	is very large.</li>

	<li>Because of VFS interface changes since kernel version
	<code>2.6.24</code> (<code>write_begin()</code> instead of
	<code>prepare_write()</code>) back-ports <code>2.6.21</code>,
	<code>2.6.22</code>, and <code>2.6.23</code> may have slightly worse
	performance comparing to the mainline code.</li>

	<li>NFS is not supported in back-ports <code>2.6.21</code>,
	<code>2.6.22</code>, <code>2.6.23</code>, and <code>2.6.24</code>.
	There is no fundamental reason for this though, it is just because the
	corresponding internal kernel interfaces changed since kernel version
	<code>2.6.25</code> and the UBIFS developers did not bother to look
	closer at how NFS support is implemented in older kernels.</li>
</ul>

<p>Thus, only <code>2.6.25</code> and <code>2.6.26</code> back-ports have full
UBIFS functionality and are not much different to the mainline UBIFS. Note, all
the back-port trees also have many MTD patches back-ported, and they have most
of the UBI changes back-ported. Also bear in mind, the back-port trees are not
going to be maintained forever and will be deleted at some point.</p>



<h2><a name="L_ml">Mailing list</a></h2>

<p>You are welcome to send feed-back, bug-reports, patches, etc to the
<a href="../mail.html">MTD mailing list</a>. Feel free to ask questions.</p>



<h2><a name="L_usptools">User-space tools</a></h2>

<p>There is only one UBIFS user-space tool at the moment -
<code>mkfs.ubifs</code>, which creates UBIFS images. The tool may be found in
the <i>MTD utils</i> repository (<code>mkfs.ubifs</code> sub-directory):</p>

<code>git://git.infradead.org/mtd-utils.git</code>

<p>The images produced by <code>mkfs.ubifs</code> may be written to
UBI volumes using <a href="ubi.html#L_usptools"><code>ubiupdatevol</code></a>
or may be further fed to the
<a href="ubi.html#L_usptools"><code>ubinize</code></a>
tool to create an UBI image which may be put to the MTD device.</p>



<h2><a name="L_scalability">Scalability</a></h2>

<p>All the data structures UBIFS is using are trees, so it scales
logarithmically in terms of flash size. However, UBI scales linearly
(see <a href="ubi.html#L_scalability">here</a>) which makes
overall UBI/UBIFS stack scalability linear. But the UBIFS authors believe it is
always possible to create logarithmically scalable UBI2 and to improve the
situation. Current UBI should be OK for 2-16GiB flashes, depending on the
I/O speed and requirements.</p>

<p>Note, although the UBI scalability is linear, it anyway scales better much
than JFFS2, which was originally designed for small ~32MiB NOR flashes. JFFS2
has scalability issues on the "file system level", while UBI/UBIFS stack has
scalability issues only on lower "raw flash level". The following table
describes the issues in more details.</p>

<table border="2" cellpadding="4" cellspacing="0">
<tr>
	<td><b>Scalability issue</b></td>
	<td><b>JFFS2</b></td><td><b>UBIFS</b></td>
</tr>

<tr>
	<td>Mount time linearly depends on the flash size</td>
	<td>True, the dependency is linear, because JFFS2 has to scan whole
	    flash media when mounting.</td>
	<td>UBIFS mount time does not depend on the flash size. But UBI needs
	    to scan the flash media, which is actually quicker than JFFS2
	    scanning. So overall, UBI/UBIFS has this linear dependency.</td>
</tr>

<tr>
	<td>Memory consumption linearly depends on the flash size</td>
	<td>True, the dependency is linear.</td>
	<td>UBIFS memory does depend on the flash size in the current
	    implementation, because the LPT shrinker is not implemented. But it
	    is not difficult to implement the LPT shrinker and get rid of the
	    dependency. It is not implemented only because the memory
	    consumption is too small to make the coding work worth it. UBI
	    memory consumption linearly depends on flash size. Thus, overall
	    UBI/UBIFS stack has the linear dependency.</td>
</tr>

<tr>
	<td>Mount time linearly depends on the file system contents</td>
	<td>True, the more data is stored on the file system, the longer it
	    takes to mount it, because JFFS2 has to do more scanning work.</td>
	<td>False, mount time does not depend on the file system contents. At
	    the worst case (if there was an unclean reboot), UBIFS has to scan
	    and replay the journal which has fixed and configurable size.</td>
</tr>

<tr>
	<td>Full file system checking is required after each mount</td>
	<td>True. JFFS2 has to check whole file system just after it has been
	    mounted in case of NAND flash. The checking involves reading all
	    nodes for each inode and checking their CRC checksums, which
	    consumes a lot of CPU. For example, this may be seen by running the
	    <code>top</code> utility just after JFFS2 has been mounted. This
	    slows down overall system boot-up time. Fundamentally, this is
	    needed because JFFS2 does not store space accounting information
	    (i.e., free/dirty space) on the flash media but instead, gathers
	    this information by scanning the flash media.</td>
	<td>False. UBIFS does not scan/check whole file system because it stores
	    the space accounting information on the flash media in the so-called
	    LPT (Logical eraseblock Properties Tree) tree.</td>
</tr>

<tr>
	<td>Memory consumption linearly depends on file system contents</td>
	<td>True. JFFS2 keeps a small data structure in RAM for each node on
	    flash, so the more data is stored on the flash media, the more
	    memory JFFS2 consumes.</td>
	<td>False. UBIFS memory consumption does not depend on how much data is
	    stored on the flash media.</td>
</tr>

<tr>
	<td>The first file access time linearly depends on its size</td>
	<td>True. JFFS2 has to keep in RAM so-called "fragment tree" for each
	    inode corresponding to an opened file. The fragment tree is an
	    in-memory RB-tree which is indexed by file offset and refers
	    on-flash nodes corresponding to this offset. The fragment tree is
	    <i>not</i> stored on the flash media. Instead, it is built
	    on-the-flight when the file is opened for the first time. To build
	    the fragment tree, JFFS2 has to read each data node corresponding
	    to this inode from the flash. This means, the larger is the file,
	    the longer it takes to open it for the first time. And the larger
	    is the file the more memory it takes when it is opened. Depending
	    on the system, JFFS2 becomes nearly unusable starting from certain
	    file size.</td>
	<td>False. UBIFS stores all the indexing information on the media in
	    the indexing B-tree. Whenever a piece of data has to be read from
	    the file system, the B-tree is looked-up and the corresponding
	    flash address to read is found. There is a TNC cache which caches
	    the B-tree nodes when the B-tree is looked-up, and the cache is
	    shrinkable, which means it might be shrunk when the kernel needs
	    more memory.</td>
</tr>

<tr>
	<td>File-system performance depends on I/O history</td>
	<td>True. Since JFFS2 is fully synchronous, it writes data to the flash
	    media as soon as the data arrives. If one changes few bytes in the
	    middle of a file, JFFS2 writes a data node which contains those
	    bytes to the flash. If there are many random small writes all
	    over the place, the file system becomes fragmented. JFFS2 merges
	    small fragments to 4KiB chunks, which involves re-compression and
	    re-writing the data. But this "de-fragmentation" is happening
	    during garbage collection and at random time, because JFFS2
	    wear-leveling algorithm is based on random eraseblock selection. So
	    if there were a lot of small writes, JFFS2 becomes slower some time
	    later - the performance just goes down out of the blue which makes
	    the system less predictable.</td>
	<td>False. UBIFS always writes in 4KiB chunks. This does not hurt the
	    performance much because of the write-back support: the data
	    changes do not go to the flash straight away - they are instead
	    deferred and are done later, when (hopefully) more data is changed
	    at the same data page and usually in background.</td>
</tr>
</table>



<h2><a name="L_writeback">Write-back support</a></h2>

<p>UBIFS supports write-back, which means that file changes do not go to the
flash media straight away, but they are cached and go to the flash later, when
it is absolutely necessary. This helps to greatly reduce the amount of I/O
which results in better performance. Write-back caching is standard technique
which exists in many modern file systems like <code>ext3</code> or
<code>XFS</code>.</p>

<p>In contrast, <code>JFFS2</code> does not have write-back support and all the
JFFS2 file system changes go the flash synchronously. Well, this is not
completely true and JFFS2 does have a small buffer of a NAND page size, but it
is small and we may treat JFFS2 as completely synchronous.</p>

<p>Write-back support requires the application programmers to take extra care
about synchronizing important files in time. Otherwise the file contents and
meta-data may corrupt or disappear in case of power-cuts, which happen very
often in many embedded devices. Let's look at what Linux manual pages say:</p>

<pre>
$ man 2 write
....
NOTES
       A  successful return from write() does not make any guarantee that data
       has been committed to disk.  In fact, on some buggy implementations, it
       does  not  even guarantee that space has successfully been reserved for
       the data.  The only way to be sure is to call fsync(2)  after  you  are
       done writing all your data.
...
</pre>

<p>This is true for UBIFS (except of the "some buggy implementations" part,
because UBIFS does reserves space for cached dirty data). Very often, people
who are accustomed to JFFS2 do not take this aspect into account and got
confused when unclean reboots corrupt their files. The following is a list
of useful hints and advices.</p>

<ul>
	<li>If you want to switch into "JFFS2 mode" and have a synchronous
	file system, use <code>-o sync</code> option when mounting UBIFS;
	however, the file system performance will drop, so this is not
	recommended unless you absolutely have to have a synchronous FS;</li>

	<li>Always keep in mind the above statement from the manual pages and
	run <code>fsync()</code> for all the important files you change; of
	course, there is no need to synchronize "throw-away" temporary files;
	Just think how important is the file data and decide;</li>

	<li>If you want to be more accurate, you may use
	<code>fdatasync()</code>, in which cases only data changes will be
	flushed, but not inode meta-data changes (e.g., "<i>mtime</i>"
	or permissions); this might be more optimal than using
	<code>fsync()</code> if the synchronization is done often, e.g., in
	a loop; otherwise just stick with  <code>fsync()</code>;</li>

	<li>In shell, the <code>sync</code> command may be used, but it
	synchronizes whole file system which might be not very optimal; and
	there is a similar <i>libc</i> <code>sync()</code> function;</li>

	<li>Alternatively to <code>fdatasync()</code> you may use
	<code>O_SYNC</code> flag of the <code>open()</code> call; this will
	make sure all the data (but not meta-data) changes go to the media
	before the <code>write()</code> operation returns;</li>

	<li>It is possible to make certain inodes to be synchronous by
	default by setting the "<i>sync</i>" flag; in a shell, the
	<code>chattr +S</code> command may be used; in <i>C</i> programs,
	use the <code>FS_IOC_SETFLAGS</code> <code>ioctl</code> command;
	Note, the <a href="ubifs.html#L_usptools"><code>mkfs.ubifs</code></a>
	tool checks for the "<i>sync</i>" flag in the original FS tree, so
	the synchronous files in the original FS tree will be synchronous in
	the resulting UBIFS image.</li>
</ul>

<p>The above items are actually true for other file systems like
<code>ext3</code>, and may even be applied to <code>JFFS2</code>.</p>

<p><code>fsync()</code> may be called for directories - it synchronizes
the directory inode meta-data. The "<i>sync</i>" flag may also be set for
directories to make the directory inode synchronous. But the flag is inherited,
which means all new children of this directory will also have this flag. New
sub-directories of this directory will also be synchronous, and their children,
and so forth. This feature is very useful if one needs to create a whole
sub-tree of synchronous files and directories, or to make all new children
of some directory to be synchronous by default (e.g., <code>/etc</code>).</p>

<p>The <code>fdatasync()</code> call for directories is "no-op" in UBIFS and
all UBIFS operations which change directory entries are synchronous.
However, it might be a good idea not to assume this for better portability
(e.g., this is not true for <code>ext2</code>). Similarly, the "<i>dirsync</i>"
inode flag has no effect in UBIFS.</p>

<p>The functions mentioned above work on file-descriptors, not on streams
(<code>FILE *</code>). To synchronize a stream, you should first get its file
descriptor using the <code>fileno()</code> <i>libc</i> function, then flush the
stream using <code>fflush()</code>, and then synchronize the file using
<code>fsync()</code> or <code>fdatasync()</code>. You may use different
synchronization methods, but remember to flush the stream before synchronizing.
The <code>fflush()</code> function flushes the <i>libc</i>-level buffers, while
<code>sync()</code>, <code>fsync()</code>, etc flush <i>kernel</i>-level
buffers.</p>

<h4>Updating a file atomically</h4>

<p>This sub-section describes the common technique of updating the contents of
a file atomically. This technique is applicable to many other UNIX
file-systems, not only to UBIFS.</p>

<p>To atomically update the contents of file <code>foo</code>, you have to
first make a copy <code>bar</code> of this file, then change file
<code>bar</code>, synchronize file <code>bar</code>, and re-name
<code>bar</code> to <code>foo</code>. Because the re-name operation is atomic
(this is a <code>POSIX</code> requirement) and <code>bar</code> is
synchronized, the whole update operation is atomic as well. Indeed, if a power
cut happens, you will end up with intact <code>foo</code> and half-updated
<code>bar</code>, in which case the whole atomic update operation may be run
again.</p>



<h2><a name="L_xattr">Extended attributes</a></h2>

<p>UBIFS supports extended attributes if the corresponding configuration option
is enabled (no additional mount options are required). It supports
<code>user</code>, <code>trusted</code>, and <code>security</code> name-spaces.
However, access control lists (ACL) support is not implemented.</p>



<h2><a name="L_mountopts">Mount options</a></h2>

<p>The following are UBIFS-specific mount options.</p>

<ul>
	<li><code>norm_unmount</code> (default) - commit on unmount; the
	journal is committed when the file system is unmounted so that the next
	mount does not have to replay the journal and it becomes very
	fast;</li>

	<li><code>fast_umount</code> - do not commit on unmount; this option
	makes unmount faster, but the next mount slower because of the need to
	replay the journal.</li>
</ul>

<p>Besides, UBIFS supports the standard <code>sync</code> mount option which
may be used to disable UBIFS write-back and write-buffer caching and make it
fully synchronous. Note, UBIFS does not support "<i>atime</i>", so the
<code>atime</code> mount option has no effect.</p>



<h2><a name="L_spaceacc">Flash space accounting issues</a></h2>

<p>Traditional file systems like <code>ext2</code> can easily calculate amount
of free space. The calculation is usually quite precise and users are
accustomed to this. However, the situation is very different in UBIFS - it
cannot really report precise amount of free space which confuses users.
Instead, it reports <i>minimum</i> amount of free space, which usually much
less than the real amount. Sometimes the mistake may be very high. For example,
UBIFS may report (via the <code>statfs()</code> system call) that there is no
free space, but one would still be able to write quite a lot.</p>

<p>To put it differently, UBIFS is often <i>lying</i> about the amount of free
space it has. As a rule, it may fit considerably more bytes than it reports.
However, it never reports more free space than it has. It reports less, and
very rarely it may report the exact amount. And this is not because UBIFS
authors are jerks, there are fundamental reasons for this, which are discussed
below.</p>

<h4>Effect of compression</h4>

<p>The first factor is UBIFS on-flight compression. Users usually seem to expect
that if file system reports <i>N</i> bytes of free space, than it is possible
to create an <i>N</i>-byte file. And because of the compression, this is not
quite true for UBIFS. Depending on how well the file data compresses, UBIFS may
fit several times more than it reports.</p>

<p>When UBIFS calculates free space, it does not a-priori know anything about
the data which is going to be written, so it cannot take into account the
compression and just always assumes the worst-case scenario when the data does
not compress.</p>

<h4>Effect of write-back</h4>

<p>The other major factor is <a href="ubi.html#L_writeback">write-back</a>.
Indeed, suppose there are <i>X</i> bytes of dirty file data in the page cache.
They will be flushed to the flash media later, and they is in RAM so far.
UBIFS (namely, the budgeting sub-system) has <i>reserved</i> <i>X</i> +
<i>O</i> bytes on the flash media for this data, where <i>O</i> is file-system
overhead (e.g., the data has to be indexed, each data node has a header,
etc).</p>

<p>The problem is that UBIFS cannot accurately calculate <i>X</i> and <i>O</i>,
and it uses pessimistic worst-case calculations, so that when the cached data
are flushed, they'll take considerably less flash space than the reserved
<i>X</i> + <i>O</i>. For example, this may lead to the following
situations.</p>

<pre>
$ df
Filesystem           1K-blocks      Used Available Use% Mounted on
ubi0:ubifs               49568     49568         0 100% /mnt/ubifs
$ sync
$ df
Filesystem           1K-blocks      Used Available Use% Mounted on
ubi0:ubifs               49568     39164      7428  85% /mnt/ubifs
</pre>

<p>First time <code>df</code> reported zero free space, but after
the <code>sync</code> it reported <code>15%</code> free space. This is because
there were a lot of cached dirty data, and UBIFS reserved all flash space
for them. But once the data has reached the flash media, they took considerably
less flash space.</p>

<p>Here are the reasons why UBIFS reserves more space than it is needed.</p>

<ul>
	<li>One of the reasons is again related to the compression. The data is
	stored in the uncompressed form in the cache, and UBIFS does know how
	well it would compress, so it assumes the data wouldn't compress at all.
	However, real-life data usually compresses quite well (unless it
	already compressed, e.g. it belongs to a <code>.tgz</code> or
	<code>.mp3</code> file). This leads to major over-estimation of the
	<i>X</i> component.</li>

	<li>Due to the design, UBIFS nodes never cross logical eraseblock (or
	LEB, see <a href="ubi.html#L_overview">here</a>) boundaries, so there
	are small spots of wasted space at the end of eraseblocks. The amount
	of this wasted flash space depends on the data and in which order this
	data has been written or changed (this will be explained more later).
	And traditionally UBIFS pessimistically assumes maximum possible amount
	of wasted space, which leads to over-estimation of the <i>O</i>
	component.</li>
</ul>

<p>Thus, UBIFS reports <i>more accurate</i> free space value if it is
synchronized.</p>

<h4>Wastage</h4>

<p>As it was mentioned above, UBIFS nodes do not cross LEB boundaries. Consider
the following numbers:</p>

<ul>
	<li>maximum UBIFS node size (non-compressed data node) is 4256
	bytes;</li>
	<li>smallest UBIFS node size (a data node with 8 bytes of data,
	corresponding to a file tail) is  56 bytes;</li>
	<li>depending on name length, directory entry nodes take 56-304
	bytes;</li>
	<li>typical LEB size in case of NAND flash with 128KiB physical
	eraseblocks and 2048 bytes NAND page is 126KiB (or 124KiB if  the NAND
	chip does not support sub-pages, see <a href="ubi.html">here</a>);</li>
</ul>

<p>Thus, if the vast majority of nodes on the flash were non-compressed data
nodes, UBIFS would waste 1344 bytes at the ends of 126KiB LEBs. But real-life
data is often compressible, so data node sizes would vary in a real-life
situation, and the amount of wasted space at the ends of eraseblocks would vary
from 0 to 4255.</p>

<p>UBIFS is doing some job to put small nodes like directory entries to the
ends of LEBs to lessen the amount of wasted space, but it is not ideal and
UBIFS still may waste unnecessarily large chunks of flash space at the ends of
eraseblocks.</p>

<p>When reporting free space, UBIFS does not know which kind of data is going
to be written to the flash media, and in which sequence. Thus, it assumes the
maximum possible wastage of 4255 bytes per LEB. This calculation is too
pessimistic for most real-life situations and the average real-life
wastage is considerably less than 4255 bytes per LEB. However, UBIFS reports
the absolute minimum amount of free space user-space applications may count
on.</p>

<p>The above means that the larger is LEB size, the better is UBIFS free space
prediction. E.g., UBIFS is better in this respect on NANDs with 128KiB
eraseblock size, comparing to NANDs with 16KiB eraseblock size.</p>

<h4>Dirty space</h4>

<p>Dirty space is the flash space occupied by UBIFS nodes which were
invalidated because they were changed or removed. For example, if the contents
of a file is re-written, than corresponding data nodes are invalidated and new
data nodes are written to the flash media. The invalidated nodes comprise dirty
space. There are other mechanisms how dirty space appears as well.</p>

<p>UBIFS cannot re-use dirty space straight away, because corresponding flash
areas do not contain all 0xFF bytes. Before dirty space can be re-used, UBIFS
has to garbage-collect corresponding LEBs. The idea of Garbage collector which
reclaims dirty space is the same as in JFFS2. Please, refer the
<a href="http://sources.redhat.com/jffs2/jffs2.pdf">JFFS2 design document</a>
for more information.</p>

<p>Roughly, UBIFS garbage collector picks a victim LEB which has some dirty
space and moves the contents of the victim LEB to the LEB which is reserved for
GC. This produces some amount of free space at the end of the reserved LEB.
Then GC pick new victim LEB, and moves the data to the reserved LEB. When the
reserved LEB is full, UBIFS picks another empty LEB (e.g., the old
victim which was made free a step ago), and continues moving nodes from the
victim LEB to the new reserved LEB. The process continues until a full empty
LEB is produced.</p>

<p>UBIFS has a notion of minimum I/O unit size, which characterizes minimum
amount of data which may be written to the flash (see
<a href="../faq/ubi.html#L_find_min_io_size">here</a> for more information).
Typically, UBIFS works on large-page NAND flashes and min. I/O size is 2KiB.</p>

<p>Consider a situation when GC picks eraseblocks with less than min. I/O unit
size dirty space. When all nodes from the victim LEB have been moved to the
reserved LEB, the last min. I/O unit of the reserved LEB has to be written to
the flash media, which means no space would be reclaimed. The reason why the
last min. I/O unit of the reserved LEB has to me written immediately is because
the victim LEB cannot be erased <i>before</i> all the moved nodes have reached
the media. Indeed, otherwise an unclean reboot would result in lost data.</p>

<p>Well, things are actually not that simple and UBIFS GC actually tries not to
waste space, but it is not always possible and UBIFS GC is far from being
ideal.</p>

<p>Anyway, what matters is that UBIFS cannot always reclaim dirty space if the
amount of it is less than min. I/O unit size. And when UBIFS calculates the
amount of free space in the file-system, it takes only large enough pieces of
dirty space into account.</p>

<p>Thus, the less dirty space the FS has, and the smaller is dirty space
fragmentation, the more precise is UBIFS free space reporting. In practice this
means that a file system which is close to be full has less accurate free
space reporting comparing to a less full file system.</p>

<p>Note, to fix this issue, UBIFS would need to run GC in
<code>statfs()</code>, which would turn as much dirty space as possible into
free space, which would result in more precise free space reporting. However,
this would make <code>statfs()</code> very slow. Another possibility would be
to implement background GC in UBIFS (just like in JFFS2).</p>



<h2><a name="L_documentation">Documentation</a></h2>

<p>The UBIFS white-paper which briefly describes main UBIFS design aspects is
available here: <a href="ubifs_whitepaper.pdf">ubifs_whitepaper.pdf</a>. There is
<a href="../faq/ubifs.html">UBIFS FAQ</a> which might be useful. Also, there is
<a href="http://osl.sed.hu/wiki/ubifs/index.php/Main_Page">a wiki page</a>, but
it has a lot of out-of-date information.</p>

<p>It might also be very useful to study
<a href="http://sources.redhat.com/jffs2/jffs2.pdf">JFFS2 design</a> because
many basic ideas are the same in UBIFS.</p>



<h2><a name="L_how_send_bugreport">How to send an UBIFS bugreport?</a></h2>

<p>Before sending a bug report, please:</p>
<ul>
	<li>make sure you have compiled kernel symbols in
	(<code>CONFIG_KALLSYMS_ALL=y</code> in <code>.config</code>);</li>

	<li>mark the <b>Enable debugging</b> check-box in the kernel
	configuration menu(<code>CONFIG_UBIFS_FS_DEBUG=y</code> in
	<code>.config</code>); Please, do not enable other debugging
	sub-options like debugging messages unless you know what you are
	doing;</li>
</ul>

<p>Then reproduce the bug (hopefully it is reproducible). Attach all the
bug-related messages including the UBIFS messages from the kernel ring buffer,
which may be collected using the <code>dmesg</code> utility or using
<code>minicom</code> with serial console capturing. And of course, it is wise
to describe how the problem can be reproduced. The bugreport should be sent to
the <a href="../mail.html">MTD mailing list</a>.</p>

<p>Note, sometimes UBIFS bugs may appear to be UBI bugs. If you suspect
there are UBI problems, please, also enable UBI debugging (see
<a href="../doc/ubi.html#L_how_send_bugreport">here</a>).</p>



<h2><a name="L_raw_vs_ftl">Raw flash vs. FTL devices</a></h2>

<p>FTL stands for "Flash Translation Layer" and it is software which emulates
a block device on top of flash hardware. At early days FTL ran on the
host computer. For example, old PCMCIA flash devices were essentially raw flash
devices, and the PCMCIA standard defined the media storage format for them. So
the host computer had to run the FTL software driver which implements PCMCIA
FTL. However, nowadays FTL is usually firmware, and it is run by the controller
which is built intro the storage device. For example, if you look inside an USB
flash drive, you'll find there a NAND chip (or several of them), and a
micro-controller, which runs FTL firmware. Some USB flash drives are known to
have quite powerful ARM processors inside. Similarly, MMC, eMMC, SD, SSD, and
other FTL devices have a built-in controller which runs FTL firmware.</p>

<p>All FTL devices have an interface which provides block I/O access. Well, the
interfaces are different and they are defined by different specifications,
e.g., MMC, eMMC, SD, USB mass storage, ATA, and so on. But all of them provide
block-based access to the device. By block-based access we mean that whole
device is represented as an linear array of (usually 512-byte) blocks. Each
block may be read or written.</p>

<p>Linux has an abstraction of a block device. For example hard drives are
block devices. Linux has many file-systems and the block I/O subsystem, which
includes elevators and so on which have been created to work with block
devices (historically - hard drives). So the idea is that the same software may
be used with FTL devices. For example, you may use FAT file-system on your MMC
card, or ext3 file-system or your SSD.</p>

<p>Although most flashes on the commodity hardware have FTL, there are systems
which have bare flashes and do not use FTL. Those are mostly various handheld
devices and embedded systems. Raw flash devices are very different to block
devices. They have different work model, they have tighter constraints and more
issues than block devices. In case of FTL devices these constraints and issues
are hidden, but in case of raw flash the software has to deal with them. Please,
refer <a href="../faq/general.html#L_mtd_vs_hdd">this</a> table for the some
more details about the difference between block devices and raw flashes.</p>

<p>UBIFS file-system has been designed for raw flash. It does work with block
devices and it assumes the raw flash device model. In other words, it assumes
the device has eraseblocks, which may be written to, read from, or erased.
UBIFS takes care of writing all data out-of-place, doing garbage-collection
and so on. UBIFS utilizes UBI, which is doing stuff like wear-leveling and
bad eraseblock handling. All these things are not normally needed for block
devices.</p>

<p>Very often people ask questions like "why would one need to use raw
flash and why not just use eMMC, or something like this?". Well, there is no
simple answer, and the following is what UBIFS developers think. Please,
take it as just our opinion and take into account the date of this writing (15
October 2008). The answer is given in a form of a list of non-structured items,
and the reader should structure and interpret it in a way which is appropriate
for his system. And because mass storage systems mostly use NAND flash (modern
FTL devices have NAND flash arrays inside), the answer talk specifically about
NAND flashes. Also, we'd like to emphasize that we do not give general
recommendations and everything depends on system requirements.</p>

<ul>
	<li>Bare NAND chips are cheaper and simpler, which is very important
	for small system. However, it seems like the industry pushes FTL
	devices forward and the situation is not that simple and obvious
	anymore. Indeed, an FTL devise is more complex than a raw NAND of
	similar size, because FTL device has to have additional controller
	and so on. But since the industry tends to produce a lot of FTL devices,
	and actually sell a lot of them, the price is going down.</li>

	<li>If you need an flash storage where you are going to use FAT file
	system, then in most cases you should stick with an FTL device (eMMC,
	MMC, SD or whatever). Just make sure the FTL device is doing proper
	wear-leveling. We believe the good brand FTL devices do it well.</li>

	<li>The other situation is when you are going to use your FTL device
	for system storage (e.g. for rootfs) and use a more robust file-system
	like ext3. In this situation you should take into account various
	system requirements like tolerance to sudden power cuts. The following
	items are mostly related to system storage situations.</li>

	<li>FTL devices are "black boxes". FTL algorithms are normally vendor
	secrets. But we know that NAND flash has issues like wear-leveling,
	bad blocks handling, read-disturb and so on. And it is important to get
	them right, especially in case of MLC NAND flash, which may have very
	short eraseblock life-time (e.g., only 1000 erase-cycles). But because
	FTL algorithms are closed, it is difficult to be sure whether a specific
	FTL device gets everything right or not.</li>

	<li>If you start thinking about how FTL could be implemented, you
	realize that it must do things like garbage collection (sometimes
	referred to as "reclaim process"). And flash hardware pretty much
	requires most writes to be out-of-place. But how does FTL behaves in
	case of sudden power-cuts? What if a power-cut happens while it is in
	the middle of doing garbage collection? Does the FTL device guarantee
	that the data which was on the flash media before the power cut happens
	will not disappear or become corrupted?</li>

	<li>The power-cut tolerance may be tested, while it is quite difficult
	to test stuff like wear-leveling or read-disturb handling, because it
	may require too much time.</li>

	<li>We have heard reports that some USB flash drives wear out very
	quickly, i.e., they start reporting I/O errors after few weeks of
	intensive use. This means that FTL does not do proper wear-leveling.
	But this does not mean that all USB flash drives are bad, but you just
	should be careful.</li>

	<li>We have heard reports that MMC and SD cards corrupt and loose data
	if power is cut during writing. Even the data which was there long time
	before may corrupt or disappear. This means that they have bad FTL
	which does not do things properly. But again, this does not have to be
	true for all MMCs and SDs - there are many different vendors. But
	again, you should be careful.</li>

	<li>In general, if you glance back into the history, many FTL devices
	were mostly used with FAT file-system for storing stuff like photo and
	video. FAT file system is not reliable by definition, which suggests
	that FTL devices may also not be very reliable, just because
	historically this was not really required. Indeed, it is not a big deal
	to loose a couple of photos. However, it is crucial to make sure that
	system libraries do not corrupt because of power-cuts.</li>

	<li>Good FTL, especially if it deals with MLC NAND (which is used in
	modern mass storage devices) must be a rather complex piece of
	software. Implementing it in firmware might be a not very simple task.
	And running it might require a powerful controller. Obviously, we may
	suspect that vendors go for various kind of tricks or compromises to
	keep their devices "good enough" and cheap. For example, it is known
	that some vendors optimize their FTL devices for FAT, and if you start
	using ext3 on top of it, you might face some unexpected problems or the
	device may become not as good as you would imagine. Again, with closed
	FTL it is often difficult to verify this..</li>

	<li>SSD drives are probably very different to eMMC, MMC/SD etc. We have
	not worked with SSD drives. They are expensive and they probably have
	powerful CPUs inside, which run complex	firmware which is probably
	getting things righ.</li>

	<li>FTL devices are becoming more popular and better, although it is
	not easy to distinguish between good and bad FTL devices (of course
	vendors would assure you their device is perfect). Generally, there
	is nothing wrong in using an FTL device as long as you trust it, or
	have tested it, or it simply fit your system requirements.</li>

	<li>In case of raw flash we exactly know what we are doing. UBI/UBIFS
	handles	all aspects of NAND flash like bad erase-blocks and
	wear-leveling. It guarantees power-cut tolerance. It is open and
	available, so you may always validate, test, and fix it. In opposite,
	it is not that simple to fix firmware bugs.</li>

	<li>Theoretically, UBIFS may do better job, because it knows much more
	information about the files than FTL. For example, UBIFS knows about
	deleted files, while FTL does not, so FTL may do unneeded work trying
	to preserve the sectors belonging to deleted files. However, some FTL
	devices support "discard" requests and may benefit from the file-system
	hints about unused sectors. Nevertheless, in general, UBIFS should do
	better job on a bare NAND, than a traditional FS on an FTL device with
	a similar NAND chip. On the other hand, FTL devices may	include
	multiple NAND chips, highly parallelise things and provide fast I/O.
	Probably SSD is a good example. But this may affect the cost.</li>

	<li>Obviously, the advantage of FTL devices is that you use old and
	trusted software on top of them.</li>
</ul>

<p>So it is indeed difficult to give an answer. Just think about cons and pros,
take into account your system requirements and decide. Nonetheless, raw flashes
are used, mostly in the embedded world, and this is why UBIFS has been
developed.</p>



<INCLUDE file="../inc/footer.tmpl" />
</PAGE>
